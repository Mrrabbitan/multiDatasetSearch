"""
è‡ªåŠ¨æ ‡æ³¨å·¥å…· - Streamlitç•Œé¢
æ”¯æŒæ‰¹é‡è‡ªåŠ¨æ£€æµ‹ã€æ ‡æ³¨ç»“æœæµè§ˆã€æ‰‹åŠ¨ç”»æ¡†æ ‡æ³¨
"""

import sys
from pathlib import Path
from typing import Dict, List, Optional

ROOT = Path(__file__).resolve().parent.parent
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))

import streamlit as st
import cv2
import numpy as np
import urllib.request
from PIL import Image

from pipeline.utils import load_yaml, resolve_path, ensure_parent_dir
from pipeline.label_auto import (
    discover_media,
    save_yolo_label,
    IMAGE_EXTS,
)
from streamlit_image_coordinates import streamlit_image_coordinates

DEFAULT_CLASSES = [
    'person', 'car', 'motorcycle', 'bus', 'truck', 'boat',
    'excavator', 'bulldozer', 'loader', 'crane', 'dump truck', 'concrete mixer',
    'trailer', 'van', 'tractor', 'forklift', 'ambulance', 'fire truck',
]

MODEL_URLS = {
    'yolov8x-worldv2.pt': 'https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x-worldv2.pt',
    'yolov8-worldv2.pt': 'https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8-worldv2.pt',
    'yolov8x.pt': 'https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x.pt',
}

DEFAULT_MODEL_DIR = "poc/data/pretrainModel"


def get_model_path(model_name: str) -> Path:
    model_dir = resolve_path(DEFAULT_MODEL_DIR)
    return model_dir / model_name


def download_model(model_name: str, model_path: Path) -> bool:
    url = MODEL_URLS.get(model_name)
    if not url:
        st.error(f"æœªçŸ¥æ¨¡å‹: {model_name}")
        return False
    try:
        st.info(f"æ­£åœ¨ä¸‹è½½æ¨¡å‹: {model_name}...")
        urllib.request.urlretrieve(url, str(model_path))
        st.success(f"æ¨¡å‹å·²ä¸‹è½½: {model_path}")
        return True
    except Exception as e:
        st.error(f"ä¸‹è½½å¤±è´¥: {e}")
        return False


def ensure_model_available(model_name: str) -> Optional[Path]:
    model_path = get_model_path(model_name)
    if model_path.exists():
        return model_path
    if download_model(model_name, model_path):
        return model_path
    return None


def yolo_labels_from_result(result, class_names):
    labels = []
    if not hasattr(result, "boxes") or result.boxes is None:
        return labels
    h, w = result.orig_shape
    for box in result.boxes:
        x1, y1, x2, y2 = box.xyxy[0].tolist()
        cls_id = int(box.cls[0].item())
        conf = float(box.conf[0].item())
        x_center = ((x1 + x2) / 2.0) / w
        y_center = ((y1 + y2) / 2.0) / h
        width = (x2 - x1) / w
        height = (y2 - y1) / h
        if isinstance(class_names, dict):
            label_name = class_names.get(cls_id, str(cls_id))
        elif isinstance(class_names, (list, tuple)) and cls_id < len(class_names):
            label_name = class_names[cls_id]
        else:
            label_name = str(cls_id)
        labels.append((cls_id, label_name, x_center, y_center, width, height, conf))
    return labels


def draw_annotations(
    image: np.ndarray,
    annotations: List[Dict],
) -> np.ndarray:
    img = image.copy()

    colors = {
        'person': (0, 255, 0),
        'truck': (255, 0, 0),
        'dump truck': (0, 128, 255),
        'excavator': (0, 0, 255),
        'car': (0, 255, 0),
        'bus': (0, 165, 255),
    }

    for ann in annotations:
        x1, y1, x2, y2 = ann['bbox']
        class_name = ann['class']
        confidence = ann.get('confidence', 1.0)
        is_manual = ann.get('manual', False)

        if is_manual:
            color = (0, 255, 0)
        else:
            color = colors.get(class_name, (255, 128, 0))

        cv2.rectangle(img, (x1, y1), (x2, y2), color, 3)

        label = f"{class_name}: {confidence:.2f}" if confidence < 1.0 else class_name
        (label_w, label_h), _ = cv2.getTextSize(
            label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2
        )

        if y1 - label_h - 10 < 0:
            bg_y1 = y1 + label_h + 10
            bg_y2 = y1
        else:
            bg_y1 = y1
            bg_y2 = y1 - label_h - 10

        cv2.rectangle(img, (x1, bg_y2), (x1 + label_w, bg_y1), color, -1)
        cv2.putText(img, label, (x1, y1 - 5 if bg_y2 < y1 else y1 + label_h - 5),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

    return img


def get_image_files(raw_images_dir: str) -> List[str]:
    image_dir = resolve_path(raw_images_dir)
    if not image_dir.exists():
        return []
    image_files = discover_media(image_dir, IMAGE_EXTS)
    return [str(p) for p in sorted(image_files)]


def batch_detect(image_files: List[str], model, confidence: float) -> Dict[str, List[Dict]]:
    results = {}
    for i, img_path in enumerate(image_files):
        try:
            result = model(img_path, conf=confidence)[0]
            labels = yolo_labels_from_result(result, model.names)

            annotations = []
            img = cv2.imread(img_path)
            if img is None:
                continue
            h, w = img.shape[:2]

            for cls_id, label_name, x_center, y_center, width, height, conf in labels:
                x1 = int((x_center - width / 2) * w)
                y1 = int((y_center - height / 2) * h)
                x2 = int((x_center + width / 2) * w)
                y2 = int((y_center + height / 2) * h)

                annotations.append({
                    'class': label_name,
                    'confidence': round(conf, 4),
                    'bbox': [x1, y1, x2, y2],
                    'manual': False,
                })

            results[img_path] = annotations
        except Exception:
            results[img_path] = []

        if (i + 1) % 10 == 0:
            st.info(f"å·²å¤„ç† {i + 1}/{len(image_files)} å¼ ...")

    return results


def render_labeling_interface():
    """æ¸²æŸ“è‡ªåŠ¨æ ‡æ³¨ç•Œé¢"""
    # æ³¨æ„ï¼šä¸è¦åœ¨è¿™é‡Œè°ƒç”¨ st.set_page_config()ï¼Œå› ä¸ºä¸»åº”ç”¨å·²ç»è®¾ç½®è¿‡äº†

    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    if 'annotations' not in st.session_state:
        st.session_state.annotations = {}
    if 'image_files' not in st.session_state:
        st.session_state.image_files = []
    if 'current_image_idx' not in st.session_state:
        st.session_state.current_image_idx = 0
    if 'detection_done' not in st.session_state:
        st.session_state.detection_done = False
    if 'model_loaded' not in st.session_state:
        st.session_state.model_loaded = False
    if 'model_path' not in st.session_state:
        st.session_state.model_path = ""
    if 'draw_start' not in st.session_state:
        st.session_state.draw_start = None
    if 'draw_end' not in st.session_state:
        st.session_state.draw_end = None
    if 'last_click' not in st.session_state:
        st.session_state.last_click = None

    annotations = st.session_state.annotations
    image_files = st.session_state.image_files

    st.header("ğŸ·ï¸ è‡ªåŠ¨æ ‡æ³¨å·¥å…·")

    # ä¾§è¾¹æ é…ç½®ï¼ˆæ³¨æ„ï¼šåœ¨ä¸»åº”ç”¨ä¸­ä¾§è¾¹æ å·²è¢«å ç”¨ï¼Œè¿™é‡Œæ”¹ä¸ºä¸»åŒºåŸŸé…ç½®ï¼‰
    st.subheader("é…ç½®")

    col_config1, col_config2 = st.columns([1, 1])

    with col_config1:
        # æ¨¡å‹é…ç½®
        st.markdown("**æ¨¡å‹è®¾ç½®**")
        config = load_yaml("poc/config/poc.yaml")
        model_name = st.selectbox(
            "é€‰æ‹©æ¨¡å‹",
            options=['yolov8x-worldv2.pt', 'yolov8-worldv2.pt', 'yolov8x.pt'],
            index=0
        )

        # æ£€æŸ¥æœ¬åœ°æ˜¯å¦æœ‰æ¨¡å‹
        model_path = get_model_path(model_name)
        local_exists = model_path.exists()

        # è‡ªåŠ¨åŠ è½½æœ¬åœ°æ¨¡å‹
        if local_exists and not st.session_state.model_loaded:
            try:
                with st.spinner("æ­£åœ¨åŠ è½½æœ¬åœ°æ¨¡å‹..."):
                    from ultralytics import YOLO
                    st.session_state.model = YOLO(str(model_path))
                    st.session_state.model_loaded = True
                    st.session_state.model_path = str(model_path)
                st.success(f"æ¨¡å‹å·²åŠ è½½: {Path(model_path).name}")
            except Exception as e:
                st.error(f"åŠ è½½å¤±è´¥: {e}")
        elif not local_exists and not st.session_state.model_loaded:
            st.warning("æœ¬åœ°æœªæ‰¾åˆ°æ¨¡å‹ï¼Œæ­£åœ¨ä¸‹è½½...")
            if ensure_model_available(model_name):
                st.rerun()

        # æ˜¾ç¤ºå½“å‰æ¨¡å‹çŠ¶æ€
        if st.session_state.model_loaded:
            st.caption(f"å½“å‰æ¨¡å‹: {Path(st.session_state.model_path).name}")

        # ç½®ä¿¡åº¦é˜ˆå€¼
        confidence = st.slider("æ£€æµ‹ç½®ä¿¡åº¦", 0.1, 0.9, 0.25)

    with col_config2:
        # è·¯å¾„é…ç½®
        st.markdown("**è·¯å¾„è®¾ç½®**")
        raw_images_dir = st.text_input(
            "å›¾åƒç›®å½•",
            value=config.get("paths", {}).get("raw_images_dir", "warning_img")
        )

        labels_dir = st.text_input(
            "æ ‡ç­¾è¾“å‡ºç›®å½•",
            value="poc/data/labels/auto"
        )
        ensure_parent_dir(resolve_path(labels_dir) / ".placeholder")

        if st.button("æ‰«æå›¾ç‰‡", use_container_width=True):
            st.session_state.image_files = get_image_files(raw_images_dir)
            st.session_state.detection_done = False
            st.session_state.current_image_idx = 0
            st.session_state.draw_start = None
            st.session_state.draw_end = None
            st.rerun()

    st.divider()

    # ä¸»å†…å®¹åŒº
    if not image_files:
        with st.spinner("æ‰«æå›¾ç‰‡ç›®å½•..."):
            st.session_state.image_files = get_image_files(raw_images_dir)
            image_files = st.session_state.image_files

    if not image_files:
        st.warning(f"æœªæ‰¾åˆ°å›¾ç‰‡")
        st.info("è¯·å°†å›¾ç‰‡æ”¾å…¥æŒ‡å®šç›®å½•ã€‚")
        return

    st.success(f"æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡")

    # æ‰¹é‡æ£€æµ‹æŒ‰é’®
    if not st.session_state.detection_done:
        st.divider()
        col_start, col_progress = st.columns([1, 3])
        with col_start:
            if st.button("å¼€å§‹æ‰¹é‡è‡ªåŠ¨æ ‡æ³¨", type="primary", use_container_width=True, disabled=not st.session_state.model_loaded):
                if not st.session_state.model_loaded:
                    st.warning("è¯·å…ˆåŠ è½½æ¨¡å‹")
                else:
                    with st.spinner("æ‰¹é‡æ£€æµ‹ä¸­ï¼Œè¯·ç¨å€™..."):
                        results = batch_detect(image_files, st.session_state.model, confidence)
                        st.session_state.annotations = results
                        st.session_state.detection_done = True
                    st.success(f"æ£€æµ‹å®Œæˆ! å…± {len(image_files)} å¼ å›¾ç‰‡")
                    st.rerun()
        with col_progress:
            if st.session_state.model_loaded:
                st.info("ç‚¹å‡»æŒ‰é’®å¼€å§‹æ‰¹é‡æ£€æµ‹æ‰€æœ‰å›¾ç‰‡")
            else:
                st.warning("è¯·å…ˆåŠ è½½æ¨¡å‹")

    # æ£€æµ‹å®Œæˆåæ˜¾ç¤ºç»“æœ
    if st.session_state.detection_done:
        # ç»Ÿè®¡ä¿¡æ¯
        total_anns = sum(len(anns) for anns in annotations.values())
        detected_count = sum(1 for anns in annotations.values() if len(anns) > 0)
        class_counts = {}
        for anns in annotations.values():
            for ann in anns:
                cls = ann['class']
                class_counts[cls] = class_counts.get(cls, 0) + 1

        st.divider()
        st.subheader("æ£€æµ‹ç»“æœç»Ÿè®¡")
        col_stat1, col_stat2, col_stat3, col_stat4 = st.columns(4)
        col_stat1.metric("æ€»å›¾ç‰‡æ•°", len(image_files))
        col_stat2.metric("æœ‰æ ‡æ³¨", detected_count)
        col_stat3.metric("æ— æ ‡æ³¨", len(image_files) - detected_count)
        col_stat4.metric("æ€»æ ‡æ³¨æ•°", total_anns)

        if class_counts:
            st.write("ç±»åˆ«åˆ†å¸ƒ:")
            st.json(class_counts)

        # å›¾ç‰‡æµè§ˆ
        st.divider()
        st.subheader("æ ‡æ³¨ç»“æœæµè§ˆä¸ç¼–è¾‘")

        current_idx = st.session_state.current_image_idx
        if current_idx >= len(image_files):
            current_idx = 0
            st.session_state.current_image_idx = 0

        col_nav1, col_nav2, col_nav3 = st.columns([2, 1, 1])
        with col_nav1:
            selected_image = st.selectbox(
                "é€‰æ‹©å›¾ç‰‡",
                range(len(image_files)),
                index=current_idx,
                format_func=lambda i: Path(image_files[i]).name
            )
            st.session_state.current_image_idx = selected_image
            # åˆ‡æ¢å›¾ç‰‡æ—¶æ¸…é™¤ç‚¹å‡»çŠ¶æ€
            if current_idx != selected_image:
                st.session_state.draw_start = None
                st.session_state.draw_end = None
                st.session_state.last_click = None
        with col_nav2:
            if st.button("ä¸Šä¸€å¼ ", disabled=selected_image == 0, use_container_width=True):
                st.session_state.current_image_idx = selected_image - 1
                st.session_state.draw_start = None
                st.session_state.draw_end = None
                st.session_state.last_click = None
                st.rerun()
        with col_nav3:
            if st.button("ä¸‹ä¸€å¼ ", disabled=selected_image == len(image_files) - 1, use_container_width=True):
                st.session_state.current_image_idx = selected_image + 1
                st.session_state.draw_start = None
                st.session_state.draw_end = None
                st.session_state.last_click = None
                st.rerun()

        current_image_path = image_files[selected_image]
        current_image_name = Path(current_image_path).stem

        # å·¥å…·æ 
        st.divider()
        col_tools1, col_tools2, col_tools3, col_tools4 = st.columns(4)

        with col_tools1:
            if st.button("é‡æ–°æ£€æµ‹å½“å‰", use_container_width=True):
                if st.session_state.model_loaded:
                    with st.spinner("æ£€æµ‹ä¸­..."):
                        img = cv2.imread(current_image_path)
                        result = st.session_state.model(current_image_path, conf=confidence)[0]
                        labels = yolo_labels_from_result(result, st.session_state.model.names)

                        anns = []
                        h, w = img.shape[:2]
                        for cls_id, label_name, x_center, y_center, width, height, conf in labels:
                            x1 = int((x_center - width / 2) * w)
                            y1 = int((y_center - height / 2) * h)
                            x2 = int((x_center + width / 2) * w)
                            y2 = int((y_center + height / 2) * h)
                            anns.append({
                                'class': label_name,
                                'confidence': round(conf, 4),
                                'bbox': [x1, y1, x2, y2],
                                'manual': False,
                            })
                        annotations[current_image_path] = anns
                    st.session_state.draw_start = None
                    st.session_state.draw_end = None
                    st.rerun()

        with col_tools2:
            if st.button("æ¸…ç©ºå½“å‰æ ‡æ³¨", use_container_width=True):
                annotations[current_image_path] = []
                st.session_state.draw_start = None
                st.session_state.draw_end = None
                st.rerun()

        with col_tools3:
            if st.button("ä¿å­˜å½“å‰", use_container_width=True):
                output_dir = resolve_path(labels_dir)
                output_dir.mkdir(parents=True, exist_ok=True)
                output_path = output_dir / f"{current_image_name}.txt"

                img = cv2.imread(current_image_path)
                if img is not None:
                    h, w = img.shape[:2]
                    yolo_labels = []
                    for ann in annotations.get(current_image_path, []):
                        x1, y1, x2, y2 = ann['bbox']
                        cls_id = DEFAULT_CLASSES.index(ann['class']) if ann['class'] in DEFAULT_CLASSES else 0
                        x_center = ((x1 + x2) / 2) / w
                        y_center = ((y1 + y2) / 2) / h
                        box_w = (x2 - x1) / w
                        box_h = (y2 - y1) / h
                        yolo_labels.append((cls_id, ann['class'], x_center, y_center, box_w, box_h, ann.get('confidence', 1.0)))
                    save_yolo_label(output_path, yolo_labels)
                    st.success("å·²ä¿å­˜")

        with col_tools4:
            if st.button("ä¿å­˜å…¨éƒ¨", use_container_width=True):
                output_dir = resolve_path(labels_dir)
                output_dir.mkdir(parents=True, exist_ok=True)
                saved_count = 0
                for img_path, anns in annotations.items():
                    img_stem = Path(img_path).stem
                    output_path = output_dir / f"{img_stem}.txt"
                    try:
                        temp_img = cv2.imread(str(img_path))
                        if temp_img is not None:
                            h, w = temp_img.shape[:2]
                            yolo_labels = []
                            for ann in anns:
                                x1, y1, x2, y2 = ann['bbox']
                                cls_id = DEFAULT_CLASSES.index(ann['class']) if ann['class'] in DEFAULT_CLASSES else 0
                                x_center = ((x1 + x2) / 2) / w
                                y_center = ((y1 + y2) / 2) / h
                                box_w = (x2 - x1) / w
                                box_h = (y2 - y1) / h
                                yolo_labels.append((cls_id, ann['class'], x_center, y_center, box_w, box_h, ann.get('confidence', 1.0)))
                            save_yolo_label(output_path, yolo_labels)
                            saved_count += 1
                    except Exception:
                        pass
                st.success(f"å·²ä¿å­˜ {saved_count} å¼ ")

        # æ‰‹åŠ¨æ ‡æ³¨åŒºåŸŸ
        st.divider()
        st.subheader("æ‰‹åŠ¨ç”»æ¡†æ ‡æ³¨")

        # åŠ è½½å›¾ç‰‡
        img = cv2.imread(current_image_path)
        if img is None:
            st.error("æ— æ³•è¯»å–å›¾ç‰‡")
            return

        h, w = img.shape[:2]

        # é€‰æ‹©ç±»åˆ«
        col_class1, col_class2 = st.columns([2, 1])
        with col_class1:
            selected_class = st.selectbox("é€‰æ‹©è¦æ ‡æ³¨çš„ç±»åˆ«", DEFAULT_CLASSES, index=0, key="draw_class")
        with col_class2:
            st.markdown("""
            **æ“ä½œæ­¥éª¤ï¼š**
            1. å…ˆç‚¹å‡»å›¾ç‰‡å·¦ä¸Šè§’
            2. å†ç‚¹å‡»å›¾ç‰‡å³ä¸‹è§’
            """)

        # è®¡ç®—æ˜¾ç¤ºå°ºå¯¸ï¼ˆç”¨äºåæ ‡è½¬æ¢ï¼‰
        max_display_width = 800
        display_width = min(w, max_display_width)
        display_height = int(h * display_width / w) if w > 0 else h

        # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹ï¼ˆæ˜¾ç¤ºåæ ‡ -> åŸå§‹åæ ‡ï¼‰
        scale_x = w / display_width
        scale_y = h / display_height

        # åœ¨åŸå§‹å›¾ç‰‡ä¸Šç»˜åˆ¶æ‰€æœ‰æ¡†ï¼ˆè‡ªåŠ¨è¯†åˆ« + æ­£åœ¨ç”»çš„ï¼‰
        annotated_img = draw_annotations(img, annotations.get(current_image_path, []))

        if st.session_state.draw_start and st.session_state.draw_end:
            x1 = min(st.session_state.draw_start[0], st.session_state.draw_end[0])
            y1 = min(st.session_state.draw_start[1], st.session_state.draw_end[1])
            x2 = max(st.session_state.draw_start[0], st.session_state.draw_end[0])
            y2 = max(st.session_state.draw_start[1], st.session_state.draw_end[1])
            cv2.rectangle(annotated_img, (x1, y1), (x2, y2), (0, 255, 0), 3)

        annotated_rgb = cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB)

        # ç¼©æ”¾åˆ°æ˜¾ç¤ºå°ºå¯¸
        annotated_rgb_resized = cv2.resize(annotated_rgb, (display_width, display_height), interpolation=cv2.INTER_AREA)

        # æ˜¾ç¤ºå›¾ç‰‡åŒºåŸŸ
        st.markdown("### ç‚¹å‡»ä¸‹æ–¹å›¾ç‰‡è¿›è¡Œæ ‡æ³¨")
        st.info(f"å›¾ç‰‡å°ºå¯¸: {w}Ã—{h} | æ˜¾ç¤ºå°ºå¯¸: {display_width}Ã—{display_height} | ç¼©æ”¾: {scale_x:.2f}Ã—{scale_y:.2f}")

        # è·å–ç‚¹å‡»åæ ‡
        coords_value = streamlit_image_coordinates(
            annotated_rgb_resized,
            key="draw_coords",
            height=display_height,
            width=display_width,
        )

        # å¤„ç†ç‚¹å‡»åæ ‡
        if coords_value is not None:
            click_x = coords_value['x']
            click_y = coords_value['y']

            # å¦‚æœæ˜¯æ— æ•ˆåæ ‡ï¼Œå¿½ç•¥
            if click_x == 0 and click_y == 0:
                pass
            else:
                last_click = st.session_state.get('last_click')

                if last_click != coords_value:
                    st.session_state.last_click = coords_value

                    # è½¬æ¢åˆ°åŸå§‹å›¾ç‰‡åæ ‡
                    orig_x = int(click_x * scale_x)
                    orig_y = int(click_y * scale_y)

                    # æ£€æŸ¥æ˜¯å¦æ˜¯ç¬¬ä¸€æ¬¡ç‚¹å‡»
                    if st.session_state.draw_start is None:
                        st.session_state.draw_start = (orig_x, orig_y)
                        st.session_state.draw_end = None
                        st.toast(f"èµ·ç‚¹å·²è®¾ç½®: ({orig_x}, {orig_y})ï¼Œè¯·ç‚¹å‡»å³ä¸‹è§’")
                        st.rerun()
                    elif st.session_state.draw_end is None:
                        # é˜²æ­¢é‡å¤ç‚¹å‡»åŒä¸€ç‚¹
                        if st.session_state.draw_start == (orig_x, orig_y):
                            st.toast("è¯·ç‚¹å‡»ä¸åŒçš„ä½ç½®ä½œä¸ºç»ˆç‚¹")
                        else:
                            st.session_state.draw_end = (orig_x, orig_y)
                            # ä¸¤ç‚¹éƒ½è·å–åæ·»åŠ æ ‡æ³¨
                            x1 = min(st.session_state.draw_start[0], st.session_state.draw_end[0])
                            y1 = min(st.session_state.draw_start[1], st.session_state.draw_end[1])
                            x2 = max(st.session_state.draw_start[0], st.session_state.draw_end[0])
                            y2 = max(st.session_state.draw_start[1], st.session_state.draw_end[1])

                            if x2 > x1 and y2 > y1 and (x2 - x1) > 10 and (y2 - y1) > 10:
                                if current_image_path not in annotations:
                                    annotations[current_image_path] = []
                                annotations[current_image_path].append({
                                    'class': selected_class,
                                    'confidence': 1.0,
                                    'bbox': [x1, y1, x2, y2],
                                    'manual': True
                                })
                                st.toast(f"å·²æ·»åŠ æ ‡æ³¨: {selected_class}")
                                st.session_state.draw_start = None
                                st.session_state.draw_end = None
                                st.session_state.last_click = None
                                st.rerun()
                            else:
                                st.warning("æ¡†å¤ªå°ï¼Œè¯·é‡æ–°ç‚¹å‡»")
                                st.session_state.draw_start = None
                                st.session_state.draw_end = None

        # æ˜¾ç¤ºå½“å‰ç”»æ¡†çŠ¶æ€
        if st.session_state.draw_start:
            sx, sy = st.session_state.draw_start
            st.warning(f"èµ·ç‚¹å·²è®¾ç½®: ({sx}, {sy})ï¼Œè¯·åœ¨å›¾ç‰‡ä¸Šç‚¹å‡»å³ä¸‹è§’")

        # å–æ¶ˆç”»æ¡†æŒ‰é’®
        if st.session_state.draw_start or st.session_state.draw_end:
            if st.button("å–æ¶ˆç”»æ¡†"):
                st.session_state.draw_start = None
                st.session_state.draw_end = None
                st.rerun()

        # æ ‡æ³¨åˆ—è¡¨
        st.divider()
        col_left, col_right = st.columns([2, 1])

        with col_left:
            st.markdown("### æ ‡æ³¨åˆ—è¡¨")
            current_annotations = annotations.get(current_image_path, [])

            if not current_annotations:
                st.info("æš‚æ— æ ‡æ³¨ï¼Œè¯·æ‰‹åŠ¨ç”»æ¡†æˆ–ç­‰å¾…è‡ªåŠ¨æ£€æµ‹")
            else:
                for idx, ann in enumerate(current_annotations):
                    is_manual = ann.get('manual', False)
                    prefix = "[æ‰‹]" if is_manual else "[è‡ªåŠ¨]"
                    conf_str = f" {ann.get('confidence', 1.0):.2f}" if ann.get('confidence', 1.0) < 1.0 else ""

                    with st.expander(f"{prefix} {ann['class']}{conf_str}", expanded=True):
                        col_a, col_b = st.columns([3, 1])
                        with col_a:
                            new_cls = st.selectbox(
                                "ç±»åˆ«",
                                DEFAULT_CLASSES,
                                index=DEFAULT_CLASSES.index(ann['class']) if ann['class'] in DEFAULT_CLASSES else 0,
                                key=f"class_{selected_image}_{idx}"
                            )
                            if new_cls != ann['class']:
                                annotations[current_image_path][idx]['class'] = new_cls
                                st.rerun()
                        with col_b:
                            if st.button("åˆ é™¤", key=f"del_{selected_image}_{idx}"):
                                annotations[current_image_path].pop(idx)
                                st.rerun()

                        x1, y1, x2, y2 = ann['bbox']
                        col_x1, col_y1 = st.columns(2)
                        with col_x1:
                            nx1 = st.number_input(f"x1##{idx}", value=x1, min_value=0, max_value=w, key=f"nx1_{idx}")
                        with col_y1:
                            ny1 = st.number_input(f"y1##{idx}", value=y1, min_value=0, max_value=h, key=f"ny1_{idx}")
                        col_x2, col_y2 = st.columns(2)
                        with col_x2:
                            nx2 = st.number_input(f"x2##{idx}", value=x2, min_value=0, max_value=w, key=f"nx2_{idx}")
                        with col_y2:
                            ny2 = st.number_input(f"y2##{idx}", value=y2, min_value=0, max_value=h, key=f"ny2_{idx}")

                        if [nx1, ny1, nx2, ny2] != [x1, y1, x2, y2]:
                            annotations[current_image_path][idx]['bbox'] = [nx1, ny1, nx2, ny2]
                            st.rerun()

        with col_right:
            st.markdown("### ä½¿ç”¨è¯´æ˜")
            st.markdown("""
            **è‡ªåŠ¨æ£€æµ‹:**
            - ç‚¹å‡»"å¼€å§‹æ‰¹é‡è‡ªåŠ¨æ ‡æ³¨"
            - è‡ªåŠ¨æ£€æµ‹æ‰€æœ‰å›¾ç‰‡

            **æ‰‹åŠ¨æ ‡æ³¨:**
            1. é€‰æ‹©ç±»åˆ«
            2. ç‚¹å‡»å›¾ç‰‡å·¦ä¸Šè§’
            3. ç‚¹å‡»å›¾ç‰‡å³ä¸‹è§’
            4. æ¡†è‡ªåŠ¨æ·»åŠ åˆ°åˆ—è¡¨

            **é¢œè‰²è¯´æ˜:**
            - ç»¿è‰² = æ‰‹åŠ¨æ ‡æ³¨
            - æ©™è‰² = è‡ªåŠ¨æ£€æµ‹

            **ç¼–è¾‘æ ‡æ³¨:**
            - å¯ä¿®æ”¹ç±»åˆ«
            - å¯è°ƒæ•´åæ ‡
            - å¯åˆ é™¤æ ‡æ³¨
            """)


def main():
    render_labeling_interface()


if __name__ == "__main__":
    main()
